# -*- coding: utf-8 -*-
# ===========================
# SageMaker LLaMA 3.2 7B Training Setup Script
# Optimized for 7B model with advanced memory management
# ===========================

import os
import subprocess
import sys
import torch
import psutil

def print_header():
    """Print setup header"""
    print("=" * 60)
    print("üöÄ SageMaker LLaMA 3.2 7B Training Setup")
    print("Optimized for 7B model with advanced memory management")
    print("=" * 60)

def check_gpu():
    """Check GPU availability and memory"""
    print("\nüîç Checking GPU availability...")
    
    if torch.cuda.is_available():
        gpu_count = torch.cuda.device_count()
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9
        
        print(f"‚úÖ GPU detected: {gpu_count} devices")
        print(f"üéØ Total GPU Memory: {gpu_memory:.1f} GB")
        
        # Display detailed GPU info
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name}")
            print(f"  Memory: {props.total_memory / 1e9:.1f} GB")
            print(f"  Compute Capability: {props.major}.{props.minor}")
        
        # Check if we have enough memory for 7B
        if gpu_memory < 15:
            print("‚ö†Ô∏è  Warning: GPU memory might be insufficient for 7B model")
            print("   Consider using CPU offloading or smaller model")
        else:
            print("‚úÖ GPU memory sufficient for 7B model")
            
        return True
    else:
        print("‚ùå No GPU detected! Training will be very slow on CPU")
        print("   Consider using a GPU instance")
        return False

def install_dependencies():
    """Install optimized dependencies for 7B model"""
    print("\nüì¶ Installing dependencies for 7B model...")
    
    # Core PyTorch with CUDA support
    print("Installing: torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    result = subprocess.run([
        "pip", "install", "--quiet", 
        "torch", "torchvision", "torchaudio", 
        "--index-url", "https://download.pytorch.org/whl/cu118"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 installed")
    else:
        print("‚ùå Failed to install PyTorch")
        print(result.stderr)
        return False
    
    # Transformers with specific version for 7B
    print("Installing: transformers==4.35.0")
    result = subprocess.run([
        "pip", "install", "--quiet", "transformers==4.35.0"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ transformers==4.35.0 installed")
    else:
        print("‚ùå Failed to install transformers")
        print(result.stderr)
        return False
    
    # Datasets with specific version
    print("Installing: datasets>=3.4.1,<4.0.0")
    result = subprocess.run([
        "pip", "install", "--quiet", "datasets>=3.4.1,<4.0.0"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ datasets>=3.4.1,<4.0.0 installed")
    else:
        print("‚ùå Failed to install datasets")
        print(result.stderr)
        return False
    
    # HuggingFace Hub
    print("Installing: huggingface_hub>=0.34.0")
    result = subprocess.run([
        "pip", "install", "--quiet", "huggingface_hub>=0.34.0"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ huggingface_hub>=0.34.0 installed")
    else:
        print("‚ùå Failed to install huggingface_hub")
        print(result.stderr)
        return False
    
    # Accelerate for distributed training
    print("Installing: accelerate")
    result = subprocess.run([
        "pip", "install", "--quiet", "accelerate"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ accelerate installed")
    else:
        print("‚ùå Failed to install accelerate")
        print(result.stderr)
        return False
    
    # PEFT for LoRA
    print("Installing: peft")
    result = subprocess.run([
        "pip", "install", "--quiet", "peft"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ peft installed")
    else:
        print("‚ùå Failed to install peft")
        print(result.stderr)
        return False
    
    # TRL for training
    print("Installing: trl")
    result = subprocess.run([
        "pip", "install", "--quiet", "trl"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ trl installed")
    else:
        print("‚ùå Failed to install trl")
        print(result.stderr)
        return False
    
    # Bitsandbytes for quantization
    print("Installing: bitsandbytes")
    result = subprocess.run([
        "pip", "install", "--quiet", "bitsandbytes"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ bitsandbytes installed")
    else:
        print("‚ùå Failed to install bitsandbytes")
        print(result.stderr)
        return False
    
    # Xformers for memory efficiency
    print("Installing: xformers")
    result = subprocess.run([
        "pip", "install", "--quiet", "xformers"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ xformers installed")
    else:
        print("‚ùå Failed to install xformers")
        print(result.stderr)
        return False
    
    # Triton for optimization
    print("Installing: triton")
    result = subprocess.run([
        "pip", "install", "--quiet", "triton"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ triton installed")
    else:
        print("‚ùå Failed to install triton")
        print(result.stderr)
        return False
    
    # TQDM for progress bars
    print("Installing: tqdm")
    result = subprocess.run([
        "pip", "install", "--quiet", "tqdm"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ tqdm installed")
    else:
        print("‚ùå Failed to install tqdm")
        print(result.stderr)
        return False
    
    # PSUTIL for memory monitoring
    print("Installing: psutil")
    result = subprocess.run([
        "pip", "install", "--quiet", "psutil"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ psutil installed")
    else:
        print("‚ùå Failed to install psutil")
        print(result.stderr)
        return False
    
    # Unsloth for optimized training
    print("Installing: unsloth")
    result = subprocess.run([
        "pip", "install", "--quiet", "unsloth"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ unsloth installed")
    else:
        print("‚ùå Failed to install unsloth")
        print(result.stderr)
        return False
    
    # Unsloth Zoo for model loading
    print("Installing: unsloth_zoo")
    result = subprocess.run([
        "pip", "install", "--quiet", "unsloth_zoo"
    ], capture_output=True, text=True)
    
    if result.returncode == 0:
        print("‚úÖ unsloth_zoo installed")
    else:
        print("‚ùå Failed to install unsloth_zoo")
        print(result.stderr)
        return False
    
    return True

def setup_memory_optimizations():
    """Setup memory optimizations for 7B model"""
    print("\nüíæ Setting up memory optimizations for 7B model...")
    
    # Set environment variables for memory optimization
    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
    
    # Set memory fraction for GPU
    if torch.cuda.is_available():
        torch.cuda.set_per_process_memory_fraction(0.85)
        print("‚úÖ GPU memory fraction set to 85%")
    
    print("‚úÖ Memory optimizations configured")

def create_directories():
    """Create necessary directories for 7B training"""
    print("\nüìÅ Creating directories for 7B training...")
    
    directories = [
        "./llama_7b_checkpoints",
        "./llama_7b_checkpoints/outputs"
    ]
    
    for directory in directories:
        os.makedirs(directory, exist_ok=True)
        print(f"‚úÖ Created: {directory}")

def verify_installation():
    """Verify all packages are installed correctly"""
    print("\nüîç Verifying installation...")
    
    try:
        import torch
        print(f"‚úÖ PyTorch: {torch.__version__}")
        print(f"‚úÖ CUDA available: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"‚úÖ CUDA version: {torch.version.cuda}")
    except ImportError:
        print("‚ùå PyTorch not installed")
        return False
    
    try:
        import transformers
        print(f"‚úÖ Transformers: {transformers.__version__}")
    except ImportError:
        print("‚ùå Transformers not installed")
        return False
    
    try:
        import datasets
        print(f"‚úÖ Datasets: {datasets.__version__}")
    except ImportError:
        print("‚ùå Datasets not installed")
        return False
    
    try:
        import huggingface_hub
        print(f"‚úÖ HuggingFace Hub: {huggingface_hub.__version__}")
    except ImportError:
        print("‚ùå HuggingFace Hub not installed")
        return False
    
    try:
        import accelerate
        print(f"‚úÖ Accelerate: {accelerate.__version__}")
    except ImportError:
        print("‚ùå Accelerate not installed")
        return False
    
    try:
        import peft
        print(f"‚úÖ PEFT: {peft.__version__}")
    except ImportError:
        print("‚ùå PEFT not installed")
        return False
    
    try:
        import trl
        print(f"‚úÖ TRL: {trl.__version__}")
    except ImportError:
        print("‚ùå TRL not installed")
        return False
    
    try:
        import bitsandbytes
        print(f"‚úÖ Bitsandbytes: {bitsandbytes.__version__}")
    except ImportError:
        print("‚ùå Bitsandbytes not installed")
        return False
    
    try:
        import xformers
        print(f"‚úÖ Xformers: {xformers.__version__}")
    except ImportError:
        print("‚ùå Xformers not installed")
        return False
    
    try:
        import unsloth
        print("‚úÖ Unsloth installed")
    except ImportError:
        print("‚ùå Unsloth not installed")
        return False
    
    try:
        import unsloth_zoo
        print("‚úÖ Unsloth Zoo installed")
    except ImportError:
        print("‚ùå Unsloth Zoo not installed")
        return False
    
    return True

def main():
    """Main setup function"""
    print_header()
    
    # Check GPU
    gpu_available = check_gpu()
    
    # Install dependencies
    if not install_dependencies():
        print("‚ùå Dependency installation failed!")
        return False
    
    # Setup memory optimizations
    setup_memory_optimizations()
    
    # Create directories
    create_directories()
    
    # Verify installation
    if not verify_installation():
        print("‚ùå Installation verification failed!")
        return False
    
    print("\n" + "=" * 60)
    print("üéâ SageMaker LLaMA 3.2 7B Setup Complete!")
    print("=" * 60)
    print("\nüìã Next Steps:")
    print("1. Upload your 'esi_data.csv' file to the SageMaker instance")
    print("2. Run the 7B training script: python sagemaker_llama_7b_training.py")
    print("3. Monitor training progress in the logs")
    print("\n‚ö†Ô∏è  Important Notes for 7B Model:")
    print("- Training will be slower than 3B model")
    print("- Memory usage will be higher")
    print("- Consider using CPU offloading if GPU memory is insufficient")
    print("- Monitor GPU memory usage during training")
    
    return True

if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
